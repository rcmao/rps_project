#!/bin/bash

# best_nemotron_solution.sh - æœ€ä½³Nemotron-3-8B-SteerLMåŠ è½½æ–¹æ¡ˆ
echo "ğŸš€ Best Solution for Nemotron-3-8B-SteerLM"
echo "ğŸ“– Based on official documentation: https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm"

# æ£€æŸ¥DockeræœåŠ¡
if ! systemctl is-active --quiet docker; then
    echo "ğŸ³ Starting Docker service..."
    systemctl start docker
    systemctl enable docker
fi

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p /root/nemotron_models
cd /root/nemotron_models

# ä¸‹è½½æ¨¡å‹ï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰
if [ ! -f "Nemotron-3-8B-Chat-4k-SteerLM.nemo" ]; then
    echo "ğŸ“¥ Downloading Nemotron model..."
    wget -O Nemotron-3-8B-Chat-4k-SteerLM.nemo \
        "https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm/resolve/main/Nemotron-3-8B-Chat-4k-SteerLM.nemo"
fi

# åˆ›å»ºå®˜æ–¹æ ¼å¼çš„æµ‹è¯•è„šæœ¬
cat > test_nemotron_official.py << 'EOF'
#!/usr/bin/env python3
import os
import sys
import torch
import time

# è®¾ç½®ç¯å¢ƒå˜é‡
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

def build_official_prompt(prompt, attributes=None):
    """æ„å»ºå®˜æ–¹SteerLMæ ¼å¼çš„prompt"""
    if attributes is None:
        # ä½¿ç”¨å®˜æ–¹æ–‡æ¡£ä¸­çš„é»˜è®¤å±æ€§
        attributes = {
            "quality": 4,
            "understanding": 4,
            "correctness": 4,
            "coherence": 4,
            "complexity": 4,
            "verbosity": 4,
            "toxicity": 0,
            "humor": 0,
            "creativity": 0,
            "violence": 0,
            "helpfulness": 4,
            "not_appropriate": 0,
            "hate_speech": 0,
            "sexual_content": 0,
            "fails_task": 0,
            "political_content": 0,
            "moral_judgement": 0,
            "lang": "en"
        }
    
    # æŒ‰ç…§å®˜æ–¹æ–‡æ¡£çš„é¡ºåºæ„å»ºå±æ€§å­—ç¬¦ä¸²
    attr_string = f"quality:{attributes['quality']},understanding:{attributes['understanding']},correctness:{attributes['correctness']},coherence:{attributes['coherence']},complexity:{attributes['complexity']},verbosity:{attributes['verbosity']},toxicity:{attributes['toxicity']},humor:{attributes['humor']},creativity:{attributes['creativity']},violence:{attributes['violence']},helpfulness:{attributes['helpfulness']},not_appropriate:{attributes['not_appropriate']},hate_speech:{attributes['hate_speech']},sexual_content:{attributes['sexual_content']},fails_task:{attributes['fails_task']},political_content:{attributes['political_content']},moral_judgement:{attributes['moral_judgement']},lang:{attributes['lang']}"
    
    # å®˜æ–¹SteerLM promptæ ¼å¼ï¼ˆæ¥è‡ªå®˜æ–¹æ–‡æ¡£ï¼‰
    official_prompt = f"""<extra_id_0>System
A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.

<extra_id_1>User
{prompt}
<extra_id_1>Assistant
<extra_id_2>{attr_string}
"""
    
    return official_prompt, attr_string

def test_with_nemo_query():
    """ä½¿ç”¨å®˜æ–¹NemoQuery APIæµ‹è¯•"""
    print("ğŸš€ Testing with official NemoQuery API...")
    
    try:
        from nemo.deploy import NemoQuery
        
        # è¿æ¥åˆ°NeMoæ¨ç†æœåŠ¡å™¨
        nq = NemoQuery(url="localhost:8000", model_name="Nemotron-3-8B-Chat-4K-SteerLM")
        
        # æµ‹è¯•ä¸åŒçš„prompt
        test_cases = [
            {
                "prompt": "Write a poem about NVIDIA in the style of Shakespeare",
                "description": "Creative Poem",
                "attributes": {
                    "quality": 4, "understanding": 4, "correctness": 4, "coherence": 4,
                    "complexity": 4, "verbosity": 4, "toxicity": 0, "humor": 0,
                    "creativity": 4, "violence": 0, "helpfulness": 4,
                    "not_appropriate": 0, "hate_speech": 0, "sexual_content": 0,
                    "fails_task": 0, "political_content": 0, "moral_judgement": 0, "lang": "en"
                }
            },
            {
                "prompt": "Explain quantum computing in simple terms",
                "description": "Educational Explanation",
                "attributes": {
                    "quality": 4, "understanding": 4, "correctness": 4, "coherence": 4,
                    "complexity": 2, "verbosity": 3, "toxicity": 0, "humor": 0,
                    "creativity": 1, "violence": 0, "helpfulness": 4,
                    "not_appropriate": 0, "hate_speech": 0, "sexual_content": 0,
                    "fails_task": 0, "political_content": 0, "moral_judgement": 0, "lang": "en"
                }
            }
        ]
        
        for i, test_case in enumerate(test_cases):
            print(f"\n{'='*60}")
            print(f"ğŸ§ª Test {i+1}: {test_case['description']}")
            print(f"{'='*60}")
            
            prompt, attr_string = build_official_prompt(test_case["prompt"], test_case["attributes"])
            
            print(f"ğŸ“ Prompt: {test_case['prompt']}")
            print(f"ğŸ“ Generated prompt:")
            print(f"```\n{prompt}\n```")
            
            # ä½¿ç”¨å®˜æ–¹APIç”Ÿæˆå“åº”
            output = nq.query_llm(
                prompts=[prompt], 
                max_output_token=200, 
                top_k=1, 
                top_p=0.0, 
                temperature=0.1
            )
            
            # åå¤„ç†è¾“å‡ºï¼ˆå®˜æ–¹æ–‡æ¡£è¦æ±‚ï¼‰
            output = [[s.split("<extra_id_1>", 1)[0].strip() for s in out] for out in output]
            
            print(f"\nğŸ¯ Generated Response:")
            print(f"```\n{output[0][0]}\n```")
            
            print(f"\nğŸ“Š Attribute string used: {attr_string}")
        
        print("\nâœ… NemoQuery API test completed!")
        return True
        
    except ImportError:
        print("âŒ NemoQuery not available.")
        return False
    except Exception as e:
        print(f"âŒ NemoQuery failed: {e}")
        return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Starting Nemotron-3-8B-SteerLM test with official approach!")
    
    if test_with_nemo_query():
        print("\nâœ… Success! Nemotron model is working correctly!")
        print("ğŸ”§ Model: nvidia/nemotron-3-8b-chat-4k-steerlm")
        print("ğŸ“š Framework: NVIDIA NeMo")
        print("ğŸ“– Documentation: https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm")
    else:
        print("\nâŒ Failed to test with NemoQuery API")
        print("ğŸ’¡ Please ensure the NeMo inference server is running")

if __name__ == "__main__":
    main()
EOF

# åˆ›å»ºå¯åŠ¨NeMoæ¨ç†æœåŠ¡å™¨çš„è„šæœ¬
cat > start_nemo_server.sh << 'EOF'
#!/bin/bash

echo "ğŸš€ Starting NeMo inference server..."

# åœæ­¢ç°æœ‰å®¹å™¨
docker stop nemotron-server 2>/dev/null || true
docker rm nemotron-server 2>/dev/null || true

# å¯åŠ¨NeMoæ¨ç†æœåŠ¡å™¨
docker run -d --name nemotron-server \
    --gpus all \
    --shm-size=16g \
    --ulimit memlock=-1 \
    --ulimit stack=67108864 \
    -p 8000:8000 \
    -v /root/nemotron_models:/workspace \
    nvcr.io/nvidia/nemo:25.02 \
    python -m nemo.deploy.inference.server \
    --model-path /workspace/Nemotron-3-8B-Chat-4k-SteerLM.nemo \
    --port 8000

echo "â³ Waiting for server to start..."
sleep 30

echo "âœ… NeMo inference server started!"
echo "ğŸŒ Server URL: http://localhost:8000"
echo "ğŸ§ª Run test: python3 test_nemotron_official.py"
EOF

chmod +x start_nemo_server.sh
chmod +x test_nemotron_official.py

echo "âœ… Best solution created!"
echo ""
echo "ğŸ“‹ Usage Instructions:"
echo "1. Start NeMo server: bash start_nemo_server.sh"
echo "2. Run test: python3 test_nemotron_official.py"
echo "3. Clean up: docker stop nemotron-server"
echo ""
echo "ğŸ”§ Model: nvidia/nemotron-3-8b-chat-4k-steerlm"
echo "ğŸ“š Framework: NVIDIA NeMo"
echo "ğŸ“– Documentation: https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm" 