
# ğŸ³ Docker ä½¿ç”¨è¯´æ˜

## å¯åŠ¨ Docker æœåŠ¡

å¦‚æœ Docker æœåŠ¡æœªè¿è¡Œï¼Œè¯·å°è¯•ä»¥ä¸‹å‘½ä»¤ï¼š

```bash
# æ–¹æ³•1ï¼šä½¿ç”¨ systemctl
sudo systemctl start docker
sudo systemctl enable docker

# æ–¹æ³•2ï¼šä½¿ç”¨ service
sudo service docker start

# æ–¹æ³•3ï¼šç›´æ¥å¯åŠ¨
sudo dockerd &
```

## ä½¿ç”¨å®˜æ–¹ NeMo å®¹å™¨

```bash
# å¯åŠ¨å®˜æ–¹ NeMo å®¹å™¨
docker run --gpus all -it --rm nvcr.io/nvidia/nemo:25.02

# åœ¨å®¹å™¨å†…è¿è¡Œ Nemotron æ¨¡å‹
python -c "
from nemo.deploy import NemoQuery
nq = NemoQuery(url='localhost:8000', model_name='Nemotron-3-8B-Chat-4K-SteerLM')
# ä½¿ç”¨å®˜æ–¹ SteerLM æ ¼å¼
"
```

## å¯åŠ¨ NeMo æ¨ç†æœåŠ¡å™¨

```bash
# å¯åŠ¨æ¨ç†æœåŠ¡å™¨
docker run -d --gpus all -p 8000:8000 nvcr.io/nvidia/nemo:25.02 \
    python -m nemo.deploy.inference.server \
    --model-path /path/to/Nemotron-3-8B-Chat-4k-SteerLM.nemo \
    --port 8000
```

## æ£€æŸ¥ Docker çŠ¶æ€

```bash
# æ£€æŸ¥ Docker ç‰ˆæœ¬
docker --version

# æ£€æŸ¥ Docker æœåŠ¡çŠ¶æ€
docker ps

# æ£€æŸ¥ GPU æ”¯æŒ
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi
```
