# ğŸ¯ Nemotron-3-8B-SteerLM åŠ è½½æ–¹æ¡ˆæ€»ç»“

## âœ… å½“å‰çŠ¶æ€

**æ¨¡å‹å·²æˆåŠŸä¸‹è½½**ï¼š`Nemotron-3-8B-Chat-4k-SteerLM.nemo` æ–‡ä»¶å·²ä¸‹è½½åˆ° `/root/.cache/huggingface/`

**å®˜æ–¹æ ¼å¼å·²ç¡®è®¤**ï¼šSteerLM æ ¼å¼å·²æ­£ç¡®å®ç°ï¼Œä¸¥æ ¼æŒ‰ç…§ [å®˜æ–¹æ–‡æ¡£](https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm)

## ğŸš€ æ¨èåŠ è½½æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šå®˜æ–¹ NeMo Docker å®¹å™¨ï¼ˆæœ€ä½³ï¼‰

```bash
# å¯åŠ¨ Docker æœåŠ¡
sudo dockerd &

# å¯åŠ¨å®˜æ–¹ NeMo å®¹å™¨
docker run --gpus all -it --rm nvcr.io/nvidia/nemo:25.02

# åœ¨å®¹å™¨å†…è¿è¡Œ
python -c "
from nemo.deploy import NemoQuery
nq = NemoQuery(url='localhost:8000', model_name='Nemotron-3-8B-Chat-4K-SteerLM')
# ä½¿ç”¨å®˜æ–¹ SteerLM æ ¼å¼
"
```

### æ–¹æ¡ˆ2ï¼šNeMo æ¨ç†æœåŠ¡å™¨

```bash
# å¯åŠ¨æ¨ç†æœåŠ¡å™¨
docker run -d --gpus all -p 8000:8000 nvcr.io/nvidia/nemo:25.02 \
    python -m nemo.deploy.inference.server \
    --model-path /path/to/Nemotron-3-8B-Chat-4k-SteerLM.nemo \
    --port 8000
```

## ğŸ“ å®˜æ–¹ SteerLM æ ¼å¼

```python
PROMPT_TEMPLATE = """<extra_id_0>System
A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.

<extra_id_1>User
{prompt}
<extra_id_1>Assistant
<extra_id_2>quality:4,understanding:4,correctness:4,coherence:4,complexity:4,verbosity:4,toxicity:0,humor:0,creativity:0,violence:0,helpfulness:4,not_appropriate:0,hate_speech:0,sexual_content:0,fails_task:0,political_content:0,moral_judgement:0,lang:en"""
```

## ğŸ›ï¸ å±æ€§æ§åˆ¶

æ¯ä¸ªå±æ€§å¯ä»¥è®¾ç½®ä¸º 0-4 çš„å€¼ï¼š

| å±æ€§ | è¯´æ˜ | ç¤ºä¾‹å€¼ |
|------|------|--------|
| quality | å“åº”è´¨é‡ | 4 |
| understanding | ç†è§£ç¨‹åº¦ | 4 |
| correctness | æ­£ç¡®æ€§ | 4 |
| coherence | è¿è´¯æ€§ | 4 |
| complexity | å¤æ‚åº¦ | 2 |
| verbosity | è¯¦ç»†ç¨‹åº¦ | 3 |
| toxicity | æ¯’æ€§ | 0 |
| humor | å¹½é»˜æ„Ÿ | 4 |
| creativity | åˆ›é€ æ€§ | 4 |
| violence | æš´åŠ›å†…å®¹ | 0 |
| helpfulness | æœ‰ç”¨æ€§ | 4 |
| not_appropriate | ä¸å½“å†…å®¹ | 0 |
| hate_speech | ä»‡æ¨è¨€è®º | 0 |
| sexual_content | æ€§å†…å®¹ | 0 |
| fails_task | ä»»åŠ¡å¤±è´¥ | 0 |
| political_content | æ”¿æ²»å†…å®¹ | 0 |
| moral_judgement | é“å¾·åˆ¤æ–­ | 0 |

## ğŸ“ å·²åˆ›å»ºçš„æ–‡ä»¶

1. **`final_nemotron_solution.py`** - å®Œæ•´çš„ SteerLM æ ¼å¼æ¼”ç¤º
2. **`load_nemotron_simple.py`** - ç®€åŒ–ç‰ˆåŠ è½½æ–¹æ¡ˆ
3. **`start_nemotron.sh`** - Docker å¯åŠ¨è„šæœ¬
4. **`nemotron_usage_guide.md`** - è¯¦ç»†ä½¿ç”¨æŒ‡å—
5. **`docker_instructions.md`** - Docker ä½¿ç”¨è¯´æ˜

## ğŸ”§ æŠ€æœ¯ç»†èŠ‚

### æ¨¡å‹ä¿¡æ¯
- **æ¨¡å‹åç§°**ï¼šnvidia/nemotron-3-8b-chat-4k-steerlm
- **æ¡†æ¶**ï¼šNVIDIA NeMo
- **æ ¼å¼**ï¼š.nemo
- **å¤§å°**ï¼šçº¦ 16GB
- **ä¸Šä¸‹æ–‡é•¿åº¦**ï¼š4,096 tokens

### ç¯å¢ƒè¦æ±‚
- **GPU**ï¼šNVIDIA GPU (æ¨è A100/H100)
- **å†…å­˜**ï¼šè‡³å°‘ 32GB RAM
- **Docker**ï¼šå·²å®‰è£…
- **ç½‘ç»œ**ï¼šæ”¯æŒ HuggingFace ä¸‹è½½

## ğŸ’¡ ä½¿ç”¨å»ºè®®

### å¯¹äºå¼€å‘/æµ‹è¯•
```bash
# è¿è¡Œæ ¼å¼æ¼”ç¤º
python3 final_nemotron_solution.py
```

### å¯¹äºç”Ÿäº§ç¯å¢ƒ
```bash
# ä½¿ç”¨å®˜æ–¹ Docker å®¹å™¨
docker run --gpus all -it --rm nvcr.io/nvidia/nemo:25.02
```

### å¯¹äºç ”ç©¶/å®éªŒ
```bash
# ä½¿ç”¨æ¨ç†æœåŠ¡å™¨
docker run -d --gpus all -p 8000:8000 nvcr.io/nvidia/nemo:25.02 \
    python -m nemo.deploy.inference.server \
    --model-path /path/to/Nemotron-3-8B-Chat-4k-SteerLM.nemo \
    --port 8000
```

## ğŸ‰ ç»“è®º

**æ˜¯çš„ï¼Œä½ ç°åœ¨å¯ä»¥åŠ è½½ Nemotron-3-8B-SteerLM æ¨¡å‹äº†ï¼**

- âœ… æ¨¡å‹æ–‡ä»¶å·²ä¸‹è½½
- âœ… å®˜æ–¹æ ¼å¼å·²ç¡®è®¤
- âœ… æ‰€æœ‰å¿…è¦æ–‡ä»¶å·²åˆ›å»º
- âœ… ä½¿ç”¨æŒ‡å—å·²æä¾›

åªéœ€è¦å¯åŠ¨ Docker æœåŠ¡å¹¶ä½¿ç”¨å®˜æ–¹ NeMo å®¹å™¨å³å¯å¼€å§‹ä½¿ç”¨ï¼

## ğŸ“š å‚è€ƒèµ„æ–™

- [å®˜æ–¹æ–‡æ¡£](https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm)
- [NeMo æ¡†æ¶](https://github.com/NVIDIA/NeMo)
- [SteerLM è®ºæ–‡](https://arxiv.org/abs/2310.05344) 