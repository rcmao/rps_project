#!/bin/bash

# start_nemotron.sh - å¯åŠ¨Nemotron-3-8B-SteerLMæ¨¡å‹
echo "ğŸš€ Starting Nemotron-3-8B-SteerLM Model"
echo "ğŸ“– Based on official documentation: https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm"

# æ£€æŸ¥DockerçŠ¶æ€
echo "ğŸ” Checking Docker status..."
if ! docker ps > /dev/null 2>&1; then
    echo "ğŸ³ Docker daemon not running. Starting Docker..."
    
    # å°è¯•å¤šç§æ–¹æ³•å¯åŠ¨Docker
    if command -v systemctl > /dev/null 2>&1; then
        echo "ğŸ“‹ Using systemctl to start Docker..."
        systemctl start docker 2>/dev/null || true
    fi
    
    if command -v service > /dev/null 2>&1; then
        echo "ğŸ“‹ Using service to start Docker..."
        service docker start 2>/dev/null || true
    fi
    
    # ç›´æ¥å¯åŠ¨Docker daemon
    echo "ğŸ“‹ Starting Docker daemon directly..."
    dockerd > /dev/null 2>&1 &
    sleep 10
    
    # æ£€æŸ¥æ˜¯å¦å¯åŠ¨æˆåŠŸ
    if docker ps > /dev/null 2>&1; then
        echo "âœ… Docker started successfully!"
    else
        echo "âŒ Failed to start Docker daemon"
        echo "ğŸ’¡ Please try manually: sudo dockerd &"
        exit 1
    fi
else
    echo "âœ… Docker is already running"
fi

# æ£€æŸ¥GPUæ”¯æŒ
echo "ğŸ” Checking GPU support..."
if docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi > /dev/null 2>&1; then
    echo "âœ… GPU support is available"
else
    echo "âš ï¸  GPU support not available, will use CPU"
fi

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p /root/nemotron_models
cd /root/nemotron_models

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
if [ ! -f "Nemotron-3-8B-Chat-4k-SteerLM.nemo" ]; then
    echo "ğŸ“¥ Model file not found. Please download it first:"
    echo "ğŸ’¡ Run: python3 load_nemotron_official.py"
    exit 1
else
    echo "âœ… Model file found: Nemotron-3-8B-Chat-4k-SteerLM.nemo"
fi

# å¯åŠ¨NeMoæ¨ç†æœåŠ¡å™¨
echo "ğŸš€ Starting NeMo inference server..."
docker stop nemotron-server 2>/dev/null || true
docker rm nemotron-server 2>/dev/null || true

# å¯åŠ¨å®¹å™¨
if docker run -d --name nemotron-server \
    --gpus all \
    --shm-size=16g \
    --ulimit memlock=-1 \
    --ulimit stack=67108864 \
    -p 8000:8000 \
    -v /root/nemotron_models:/workspace \
    nvcr.io/nvidia/nemo:25.02 \
    python -m nemo.deploy.inference.server \
    --model-path /workspace/Nemotron-3-8B-Chat-4k-SteerLM.nemo \
    --port 8000; then
    
    echo "âœ… NeMo inference server started successfully!"
    echo "ğŸŒ Server URL: http://localhost:8000"
    echo "â³ Waiting for server to be ready..."
    sleep 30
    
    # åˆ›å»ºæµ‹è¯•è„šæœ¬
    cat > test_nemotron_client.py << 'EOF'
#!/usr/bin/env python3
import time
import requests

def test_nemotron_server():
    """æµ‹è¯•NemotronæœåŠ¡å™¨"""
    print("ğŸ§ª Testing Nemotron server...")
    
    try:
        # æµ‹è¯•æœåŠ¡å™¨è¿æ¥
        response = requests.get("http://localhost:8000/health", timeout=10)
        if response.status_code == 200:
            print("âœ… Server is healthy!")
            return True
        else:
            print(f"âŒ Server returned status: {response.status_code}")
            return False
    except Exception as e:
        print(f"âŒ Failed to connect to server: {e}")
        return False

def build_official_prompt(prompt, attributes=None):
    """æ„å»ºå®˜æ–¹SteerLMæ ¼å¼çš„prompt"""
    if attributes is None:
        attributes = {
            "quality": 4, "understanding": 4, "correctness": 4, "coherence": 4,
            "complexity": 4, "verbosity": 4, "toxicity": 0, "humor": 0,
            "creativity": 0, "violence": 0, "helpfulness": 4,
            "not_appropriate": 0, "hate_speech": 0, "sexual_content": 0,
            "fails_task": 0, "political_content": 0, "moral_judgement": 0, "lang": "en"
        }
    
    attr_string = f"quality:{attributes['quality']},understanding:{attributes['understanding']},correctness:{attributes['correctness']},coherence:{attributes['coherence']},complexity:{attributes['complexity']},verbosity:{attributes['verbosity']},toxicity:{attributes['toxicity']},humor:{attributes['humor']},creativity:{attributes['creativity']},violence:{attributes['violence']},helpfulness:{attributes['helpfulness']},not_appropriate:{attributes['not_appropriate']},hate_speech:{attributes['hate_speech']},sexual_content:{attributes['sexual_content']},fails_task:{attributes['fails_task']},political_content:{attributes['political_content']},moral_judgement:{attributes['moral_judgement']},lang:{attributes['lang']}"
    
    official_prompt = f"""<extra_id_0>System
A chat between a curious user and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the user's questions.

<extra_id_1>User
{prompt}
<extra_id_1>Assistant
<extra_id_2>{attr_string}
"""
    
    return official_prompt

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ Testing Nemotron-3-8B-SteerLM server...")
    
    # æµ‹è¯•æœåŠ¡å™¨
    if test_nemotron_server():
        print("\nâœ… Nemotron server is ready!")
        print("ğŸ”§ Model: nvidia/nemotron-3-8b-chat-4k-steerlm")
        print("ğŸ“š Framework: NVIDIA NeMo")
        print("ğŸ“– Documentation: https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm")
        print("\nğŸ’¡ You can now use the model with the official SteerLM format!")
    else:
        print("\nâŒ Server is not ready yet. Please wait and try again.")
        print("ğŸ’¡ You can check server logs with: docker logs nemotron-server")

if __name__ == "__main__":
    main()
EOF

    chmod +x test_nemotron_client.py
    
    # è¿è¡Œæµ‹è¯•
    echo "ğŸ§ª Running server test..."
    python3 test_nemotron_client.py
    
    echo ""
    echo "ğŸ“‹ Usage Instructions:"
    echo "1. Test server: python3 test_nemotron_client.py"
    echo "2. Stop server: docker stop nemotron-server"
    echo "3. View logs: docker logs nemotron-server"
    echo ""
    echo "ğŸ”§ Model: nvidia/nemotron-3-8b-chat-4k-steerlm"
    echo "ğŸ“š Framework: NVIDIA NeMo"
    echo "ğŸ“– Documentation: https://huggingface.co/nvidia/nemotron-3-8b-chat-4k-steerlm"
    
else
    echo "âŒ Failed to start NeMo inference server"
    echo "ğŸ’¡ Please check Docker and GPU availability"
    exit 1
fi 